},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis {#performance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance attribution\n",
    "if results:\n",
    "    returns = results['returns']\n",
    "    \n",
    "    # Monthly performance analysis\n",
    "    monthly_returns = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    print(\"üìÖ Monthly Performance Summary:\")\n",
    "    print(f\"  Best Month: {monthly_returns.max():.2%} ({monthly_returns.idxmax().strftime('%Y-%m')})\")\n",
    "    print(f\"  Worst Month: {monthly_returns.min():.2%} ({monthly_returns.idxmin().strftime('%Y-%m')})\")\n",
    "    print(f\"  Positive Months: {(monthly_returns > 0).sum()} / {len(monthly_returns)} ({(monthly_returns > 0).mean():.1%})\")\n",
    "    \n",
    "    # Yearly performance analysis\n",
    "    yearly_returns = returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    print(\"\\nüìä Yearly Performance:\")\n",
    "    for year, ret in yearly_returns.items():\n",
    "        print(f\"  {year.year}: {ret:.2%}\")\n",
    "    \n",
    "    # Risk-adjusted metrics by year\n",
    "    yearly_metrics = []\n",
    "    for year in yearly_returns.index:\n",
    "        year_data = returns[returns.index.year == year.year]\n",
    "        if len(year_data) > 10:  # Minimum observations\n",
    "            sharpe = year_data.mean() / year_data.std() * np.sqrt(252) if year_data.std() > 0 else 0\n",
    "            yearly_metrics.append({\n",
    "                'Year': year.year,\n",
    "                'Return': yearly_returns[year],\n",
    "                'Volatility': year_data.std() * np.sqrt(252),\n",
    "                'Sharpe': sharpe,\n",
    "                'Max DD': ((1 + year_data).cumprod() / (1 + year_data).cumprod().expanding().max() - 1).min()\n",
    "          {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook demonstrates the comprehensive capabilities of **AlphaForge** - a systematic alpha research platform:\n",
    "\n",
    "### üéØ Key Features Demonstrated:\n",
    "1. **üîó Data Integration**: Seamless multi-source data fetching with intelligent caching\n",
    "2. **‚öôÔ∏è Factor Engineering**: Classic factors (momentum, value, quality, size, low-vol) with robust calculation\n",
    "3. **üé™ Portfolio Construction**: Long-short strategies with position limits and risk controls\n",
    "4. **üß† Advanced Techniques**: Bayesian shrinkage and Lasso regularization for overfitting prevention\n",
    "5. **üî¨ Rigorous Testing**: Walk-forward analysis for unbiased out-of-sample validation\n",
    "6. **üìä Comprehensive Analytics**: Risk metrics, performance attribution, and sensitivity analysis\n",
    "\n",
    "### üöÄ Next Steps for Research:\n",
    "- **Custom Factors**: Develop proprietary signals using the extensible framework\n",
    "- **ML Integration**: Implement ensemble methods and deep learning models\n",
    "- **Alternative Data**: Incorporate sentiment, satellite, and patent data\n",
    "- **Multi-Asset**: Extend to fixed income, commodities, and currencies\n",
    "- **Regime Models**: Add market regime detection and adaptive strategies\n",
    "\n",
    "### üíº Framework Benefits:\n",
    "- **üèóÔ∏è Modular Design**: Easy to extend and customize for specific research needs\n",
    "- **‚ö° Performance**: Parallel processing and caching for institutional-scale research\n",
    "- **üõ°Ô∏è Robust**: Transaction costs, survivorship bias, and statistical validation\n",
    "- **üìà Research-Ready**: Publication-quality analytics and visualizations\n",
    "\n",
    "### üî• Production Applications:\n",
    "- **Hedge Funds**: Systematic strategy development and risk management\n",
    "- **Asset Managers**: Portfolio optimization and performance attribution\n",
    "- **Risk Teams**: Factor exposure monitoring and stress testing\n",
    "- **Academic Research**: Empirical asset pricing and factor model validation\n",
    "\n",
    "**AlphaForge** provides a professional-grade foundation for systematic alpha research that scales from academic studies to institutional trading strategies.\n",
    "\n",
    "---\n",
    "\n",
    "üöÄ **Ready to forge alpha?** Explore the examples directory for advanced use cases and custom factor development patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}\n",
    "    \n",
    "    yearly_df = pd.DataFrame(yearly_metrics)\n",
    "    display(yearly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk analysis\n",
    "if results:\n",
    "    returns = results['returns']\n",
    "    \n",
    "    # Value at Risk (VaR) analysis\n",
    "    var_95 = np.percentile(returns, 5)\n",
    "    var_99 = np.percentile(returns, 1)\n",
    "    cvar_95 = returns[returns <= var_95].mean()\n",
    "    \n",
    "    print(\"‚ö†Ô∏è Risk Metrics:\")\n",
    "    print(f\"  Daily VaR (95%): {var_95:.2%}\")\n",
    "    print(f\"  Daily VaR (99%): {var_99:.2%}\")\n",
    "    print(f\"  Conditional VaR (95%): {cvar_95:.2%}\")\n",
    "    \n",
    "    # Tail risk analysis\n",
    "    extreme_losses = returns[returns < np.percentile(returns, 5)]\n",
    "    extreme_gains = returns[returns > np.percentile(returns, 95)]\n",
    "    \n",
    "    print(f\"\\nüìä Tail Analysis:\")\n",
    "    print(f\"  Extreme Loss Days: {len(extreme_losses)}\")\n",
    "    print(f\"  Average Extreme Loss: {extreme_losses.mean():.2%}\")\n",
    "    print(f\"  Extreme Gain Days: {len(extreme_gains)}\")\n",
    "    print(f\"  Average Extreme Gain: {extreme_gains.mean():.2%}\")\n",
    "    \n",
    "    # Risk visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # VaR visualization\n",
    "    axes[0, 0].hist(returns, bins=50, alpha=0.7, density=True)\n",
    "    axes[0, 0].axvline(var_95, color='red', linestyle='--', label=f'VaR 95%: {var_95:.2%}')\n",
    "    axes[0, 0].axvline(var_99, color='darkred', linestyle='--', label=f'VaR 99%: {var_99:.2%}')\n",
    "    axes[0, 0].set_title('Return Distribution with VaR')\n",
    "    axes[0, 0].set_xlabel('Return')\n",
    "    axes[0, 0].set_ylabel('Density')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Rolling volatility\n",
    "    rolling_vol = returns.rolling(30).std() * np.sqrt(252)\n",
    "    axes[0, 1].plot(rolling_vol.index, rolling_vol.values)\n",
    "    axes[0, 1].set_title('Rolling 30-Day Volatility')\n",
    "    axes[0, 1].set_ylabel('Annualized Volatility')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Underwater plot (drawdown)\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    running_max = cum_returns.expanding().max()\n",
    "    underwater = (cum_returns / running_max - 1) * 100\n",
    "    axes[1, 0].fill_between(underwater.index, underwater.values, 0, alpha=0.3, color='red')\n",
    "    axes[1, 0].set_title('Underwater Plot (Drawdown %)')\n",
    "    axes[1, 0].set_ylabel('Drawdown (%)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Monthly returns heatmap\n",
    "    monthly_rets = returns.resample('M').apply(lambda x: (1 + x).prod() - 1) * 100\n",
    "    monthly_rets.index = monthly_rets.index.to_period('M')\n",
    "    \n",
    "    # Create pivot table for heatmap\n",
    "    heatmap_data = monthly_rets.to_frame('Return')\n",
    "    heatmap_data['Year'] = heatmap_data.index.year\n",
    "    heatmap_data['Month'] = heatmap_data.index.month\n",
    "    heatmap_pivot = heatmap_data.pivot(index='Year', columns='Month', values='Return')\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(heatmap_pivot, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                ax=axes[1, 1], cbar_kws={'label': 'Monthly Return (%)'})\n",
    "    axes[1, 1].set_title('Monthly Returns Heatmap')\n",
    "    axes[1, 1].set_xlabel('Month')\n",
    "    axes[1, 1].set_ylabel('Year')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Techniques {#advanced}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different regularization techniques\n",
    "print(\"üî¨ Comparing Regularization Techniques...\")\n",
    "\n",
    "# Run backtests with different configurations\n",
    "configs = [\n",
    "    {'name': 'No Regularization', 'shrinkage': False, 'lasso': False},\n",
    "    {'name': 'Bayesian Shrinkage Only', 'shrinkage': True, 'lasso': False},\n",
    "    {'name': 'Lasso Only', 'shrinkage': False, 'lasso': True},\n",
    "    {'name': 'Both Techniques', 'shrinkage': True, 'lasso': True}\n",
    "]\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for config_dict in configs:\n",
    "    print(f\"Running: {config_dict['name']}...\")\n",
    "    \n",
    "    result = backtester.run_backtest(\n",
    "        tickers=tickers[:50],  # Use smaller universe for speed\n",
    "        use_shrinkage=config_dict['shrinkage'],\n",
    "        use_lasso=config_dict['lasso']\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        comparison_results.append({\n",
    "            'Strategy': config_dict['name'],\n",
    "            'Total Return': result['metrics']['total_return'],\n",
    "            'Annualized Return': result['metrics']['annualized_return'],\n",
    "            'Volatility': result['metrics']['volatility'],\n",
    "            'Sharpe Ratio': result['metrics']['sharpe_ratio'],\n",
    "            'Max Drawdown': result['metrics']['max_drawdown'],\n",
    "            'Win Rate': result['metrics']['win_rate']\n",
    "        })\n",
    "\n",
    "# Display comparison\n",
    "if comparison_results:\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Sharpe Ratio comparison\n",
    "    axes[0, 0].bar(comparison_df['Strategy'], comparison_df['Sharpe Ratio'], alpha=0.7)\n",
    "    axes[0, 0].set_title('Sharpe Ratio by Strategy')\n",
    "    axes[0, 0].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Return vs Risk\n",
    "    axes[0, 1].scatter(comparison_df['Volatility'], comparison_df['Annualized Return'], \n",
    "                      s=100, alpha=0.7)\n",
    "    for i, txt in enumerate(comparison_df['Strategy']):\n",
    "        axes[0, 1].annotate(txt, (comparison_df['Volatility'].iloc[i], \n",
    "                                 comparison_df['Annualized Return'].iloc[i]),\n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    axes[0, 1].set_title('Risk-Return Profile')\n",
    "    axes[0, 1].set_xlabel('Volatility')\n",
    "    axes[0, 1].set_ylabel('Annualized Return')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Max Drawdown comparison\n",
    "    axes[1, 0].bar(comparison_df['Strategy'], comparison_df['Max Drawdown'], \n",
    "                   color='red', alpha=0.7)\n",
    "    axes[1, 0].set_title('Maximum Drawdown by Strategy')\n",
    "    axes[1, 0].set_ylabel('Max Drawdown')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Win Rate comparison\n",
    "    axes[1, 1].bar(comparison_df['Strategy'], comparison_df['Win Rate'], \n",
    "                   color='green', alpha=0.7)\n",
    "    axes[1, 1].set_title('Win Rate by Strategy')\n",
    "    axes[1, 1].set_ylabel('Win Rate')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor importance analysis\n",
    "if results and 'factor_data' in results:\n",
    "    factor_data = results['factor_data']\n",
    "    \n",
    "    # Calculate factor importance using correlation with future returns\n",
    "    factor_cols = ['momentum_rank', 'value_rank', 'quality_rank', 'size_rank', 'low_vol_rank']\n",
    "    \n",
    "    # Calculate next period returns\n",
    "    factor_data['next_return'] = factor_data.groupby('ticker')['returns'].shift(-1)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    factor_importance = {}\n",
    "    for factor in factor_cols:\n",
    "        if factor in factor_data.columns:\n",
    "            corr = factor_data[factor].corr(factor_data['next_return'])\n",
    "            factor_importance[factor.replace('_rank', '')] = abs(corr)\n",
    "    \n",
    "    print(\"üìä Factor Importance (Correlation with Future Returns):\")\n",
    "    importance_df = pd.DataFrame(list(factor_importance.items()), \n",
    "                                columns=['Factor', 'Importance'])\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    display(importance_df)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(importance_df['Factor'], importance_df['Importance'], alpha=0.7)\n",
    "    plt.title('Factor Importance (Absolute Correlation with Future Returns)')\n",
    "    plt.xlabel('Factor')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis - different rebalancing frequencies\n",
    "print(\"üìä Sensitivity Analysis - Rebalancing Frequency\")\n",
    "\n",
    "rebalance_frequencies = ['M', 'Q']  # Monthly, Quarterly\n",
    "freq_results = []\n",
    "\n",
    "for freq in rebalance_frequencies:\n",
    "    print(f\"Testing {freq} rebalancing...\")\n",
    "    \n",
    "    # Create new config\n",
    "    freq_config = BacktestConfig(\n",
    "        start_date=config.start_date,\n",
    "        end_date=config.end_date,\n",
    "        rebalance_freq=freq,\n",
    "        transaction_cost=config.transaction_cost,\n",
    "        max_weight=config.max_weight,\n",
    "        min_weight=config.min_weight\n",
    "    )\n",
    "    \n",
    "    # Run backtest\n",
    "    freq_backtester = Backtester(freq_config)\n",
    "    result = freq_backtester.run_backtest(tickers=tickers[:30], \n",
    "                                         use_shrinkage=True, use_lasso=True)\n",
    "    \n",
    "    if result:\n",
    "        freq_results.append({\n",
    "            'Frequency': freq,\n",
    "            'Annualized Return': result['metrics']['annualized_return'],\n",
    "            'Volatility': result['metrics']['volatility'],\n",
    "            'Sharpe Ratio': result['metrics']['sharpe_ratio'],\n",
    "            'Max Drawdown': result['metrics']['max_drawdown'],\n",
    "            'Avg Transaction Cost': result['transaction_costs'].mean()\n",
    "        })\n",
    "\n",
    "if freq_results:\n",
    "    freq_df = pd.DataFrame(freq_results)\n",
    "    display(freq_df)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Performance comparison\n",
    "    x = np.arange(len(freq_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[0].bar(x - width, freq_df['Annualized Return'], width, label='Return', alpha=0.7)\n",
    "    axes[0].bar(x, freq_df['Volatility'], width, label='Volatility', alpha=0.7)\n",
    "    axes[0].bar(x + width, freq_df['Sharpe Ratio']/10, width, label='Sharpe/10', alpha=0.7)\n",
    "    \n",
    "    axes[0].set_xlabel('Rebalancing Frequency')\n",
    "    axes[0].set_ylabel('Value')\n",
    "    axes[0].set_title('Performance by Rebalancing Frequency')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(freq_df['Frequency'])\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Transaction costs\n",
    "    axes[1].bar(freq_df['Frequency'], freq_df['Avg Transaction Cost'], \n",
    "               color='red', alpha=0.7)\n",
    "    axes[1].set_title('Average Transaction Costs')\n",
    "    axes[1].set_ylabel('Transaction Cost')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook demonstrates the comprehensive capabilities of our factor model backtesting framework:\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "1. **Data Integration**: Seamless data fetching from Yahoo Finance with caching\n",
    "2. **Factor Engineering**: Calculation of classic factors (momentum, value, quality, size, low-vol)\n",
    "3. **Portfolio Construction**: Long-short portfolio with position limits and risk controls\n",
    "4. **Advanced Techniques**: Bayesian shrinkage and Lasso regularization\n",
    "5. **Robust Testing**: Walk-forward analysis for out-of-sample validation\n",
    "6. **Comprehensive Analytics**: Risk metrics, performance attribution, and sensitivity analysis\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different factor combinations\n",
    "- Add custom factors specific to your research\n",
    "- Implement alternative portfolio construction methods\n",
    "- Extend to other asset classes or markets\n",
    "- Add regime-aware models\n",
    "\n",
    "### Framework Benefits:\n",
    "- **Modular Design**: Easy to extend and customize\n",
    "- **Performance**: Parallel processing and caching for efficiency\n",
    "- **Robust**: Transaction costs, survivorship bias considerations\n",
    "- **Research-Ready**: Comprehensive analytics and visualizations\n",
    "\n",
    "The framework provides a solid foundation for factor-based research and can be easily adapted for different research questions and trading strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaForge Research Notebook üöÄ\n",
    "\n",
    "**Interactive environment for systematic alpha research and factor model validation**\n",
    "\n",
    "This notebook demonstrates the full capabilities of AlphaForge for quantitative factor research, portfolio construction, and performance analysis.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#setup)\n",
    "2. [Factor Analysis](#factors)\n",
    "3. [Portfolio Construction](#portfolio)\n",
    "4. [Backtesting](#backtest)\n",
    "5. [Walk-Forward Analysis](#walkforward)\n",
    "6. [Performance Analysis](#performance)\n",
    "7. [Advanced Techniques](#advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import AlphaForge framework\n",
    "from factor_backtester import (\n",
    "    Backtester, BacktestConfig, DataProvider, \n",
    "    FactorCalculator, PortfolioConstructor, \n",
    "    PerformanceAnalyzer\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üöÄ AlphaForge Research Environment Ready!\")\n",
    "print(\"üìä Systematic alpha research toolkit loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlphaForge Configuration\n",
    "config = BacktestConfig(\n",
    "    start_date=\"2015-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    "    rebalance_freq=\"M\",  # Monthly rebalancing\n",
    "    transaction_cost=0.001,  # 10 bps transaction cost\n",
    "    max_weight=0.05,  # 5% max position\n",
    "    min_weight=-0.05,  # 5% max short position\n",
    "    leverage=1.0  # No leverage\n",
    ")\n",
    "\n",
    "# Initialize AlphaForge components\n",
    "data_provider = DataProvider()\n",
    "backtester = Backtester(config)\n",
    "\n",
    "print(f\"‚öôÔ∏è AlphaForge Configuration:\")\n",
    "print(f\"   üìÖ Period: {config.start_date} to {config.end_date}\")\n",
    "print(f\"   üîÑ Rebalancing: {config.rebalance_freq}\")\n",
    "print(f\"   üí∞ Transaction Cost: {config.transaction_cost:.1%}\")\n",
    "print(f\"   üìä Position Limits: {config.min_weight:.1%} to {config.max_weight:.1%}\")\n",
    "print(f\"   üéØ Leverage: {config.leverage}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market universe\n",
    "print(\"üìà Loading S&P 500 universe...\")\n",
    "tickers = data_provider.get_universe(\"SP500\")\n",
    "print(f\"üåü Universe: {len(tickers)} stocks\")\n",
    "print(f\"üìã Sample tickers: {tickers[:15]}\")\n",
    "\n",
    "# Fetch market data with caching\n",
    "print(\"\\nüîÑ Fetching market data (this may take a moment)...\")\n",
    "raw_data = data_provider.fetch_yahoo_data(tickers, config.start_date, config.end_date)\n",
    "print(f\"‚úÖ Loaded {len(raw_data):,} observations\")\n",
    "print(f\"üìä {len(raw_data['ticker'].unique())} unique tickers\")\n",
    "print(f\"üìÖ Date range: {raw_data['Date'].min()} to {raw_data['Date'].max()}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "display(raw_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Factor Analysis {#factors}\n",
    "\n",
    "Calculate and analyze classic risk factors using AlphaForge's factor engineering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate factors using AlphaForge\n",
    "print(\"üî¨ Calculating systematic risk factors...\")\n",
    "factor_calculator = FactorCalculator(raw_data)\n",
    "factor_data = factor_calculator.calculate_all_factors()\n",
    "\n",
    "print(f\"üìä Factor data shape: {factor_data.shape}\")\n",
    "print(f\"üìÖ Factor coverage: {factor_data['Date'].min()} to {factor_data['Date'].max()}\")\n",
    "print(f\"üéØ {len(factor_data['ticker'].unique())} stocks with factor scores\")\n",
    "\n",
    "# Display factor summary statistics\n",
    "factor_cols = ['momentum', 'value', 'quality', 'size', 'low_vol']\n",
    "print(\"\\nüìà Factor Summary Statistics:\")\n",
    "factor_summary = factor_data[factor_cols].describe()\n",
    "display(factor_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor correlation and distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Factor correlation heatmap\n",
    "corr_matrix = factor_data[factor_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, ax=axes[0, 0], fmt='.3f')\n",
    "axes[0, 0].set_title('üìä Factor Correlation Matrix')\n",
    "\n",
    "# Factor rank distributions\n",
    "factor_ranks = [col + '_rank' for col in factor_cols if col + '_rank' in factor_data.columns]\n",
    "if factor_ranks:\n",
    "    factor_data[factor_ranks].hist(bins=50, ax=axes[0, 1], alpha=0.7)\n",
    "    axes[0, 1].set_title('üìà Factor Rank Distributions')\n",
    "\n",
    "# Factor stability over time (cross-sectional means)\n",
    "factor_ts = factor_data.groupby('Date')[factor_cols].mean()\n",
    "for factor in factor_cols:\n",
    "    axes[1, 0].plot(factor_ts.index, factor_ts[factor], label=factor.title(), alpha=0.8)\n",
    "axes[1, 0].set_title('üîÑ Factor Evolution Over Time')\n",
    "axes[1, 0].set_ylabel('Cross-Sectional Mean')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Factor volatility\n",
    "factor_vol = factor_data.groupby('Date')[factor_cols].std().mean()\n",
    "factor_vol.plot(kind='bar', ax=axes[1, 1], alpha=0.7)\n",
    "axes[1, 1].set_title('üìä Average Factor Volatility')\n",
    "axes[1, 1].set_ylabel('Cross-Sectional Std Dev')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Portfolio Construction {#portfolio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio construction example\n",
    "portfolio_constructor = PortfolioConstructor(config)\n",
    "\n",
    "# Select a sample date\n",
    "sample_date = factor_data['Date'].iloc[500]  # Mid-sample date\n",
    "print(f\"üìÖ Sample portfolio construction date: {sample_date}\")\n",
    "\n",
    "# Construct portfolio\n",
    "weights = portfolio_constructor.construct_portfolio(\n",
    "    factor_data, sample_date, use_shrinkage=True, use_lasso=True\n",
    ")\n",
    "\n",
    "print(f\"üìä Portfolio statistics:\")\n",
    "print(f\"  Total positions: {len(weights)}\")\n",
    "print(f\"  Long positions: {(weights > 0).sum()}\")\n",
    "print(f\"  Short positions: {(weights < 0).sum()}\")\n",
    "print(f\"  Total long weight: {weights[weights > 0].sum():.2%}\")\n",
    "print(f\"  Total short weight: {weights[weights < 0].sum():.2%}\")\n",
    "print(f\"  Net exposure: {weights.sum():.2%}\")\n",
    "print(f\"  Gross exposure: {weights.abs().sum():.2%}\")\n",
    "\n",
    "# Display top and bottom holdings\n",
    "print(\"\\nüîù Top 10 Long Positions:\")\n",
    "display(weights.nlargest(10).to_frame('Weight'))\n",
    "\n",
    "print(\"\\nüîª Top 10 Short Positions:\")\n",
    "display(weights.nsmallest(10).to_frame('Weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio weights\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Weight distribution\n",
    "axes[0, 0].hist(weights, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Portfolio Weight Distribution')\n",
    "axes[0, 0].set_xlabel('Weight')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Long vs Short\n",
    "long_weights = weights[weights > 0]\n",
    "short_weights = weights[weights < 0]\n",
    "axes[0, 1].bar(['Long', 'Short'], [long_weights.sum(), short_weights.sum()], \n",
    "               color=['green', 'red'], alpha=0.7)\n",
    "axes[0, 1].set_title('Long vs Short Exposure')\n",
    "axes[0, 1].set_ylabel('Total Weight')\n",
    "\n",
    "# Top positions\n",
    "top_positions = weights.abs().nlargest(15)\n",
    "colors = ['green' if weights[ticker] > 0 else 'red' for ticker in top_positions.index]\n",
    "axes[1, 0].barh(range(len(top_positions)), top_positions.values, color=colors, alpha=0.7)\n",
    "axes[1, 0].set_yticks(range(len(top_positions)))\n",
    "axes[1, 0].set_yticklabels(top_positions.index, fontsize=8)\n",
    "axes[1, 0].set_title('Top 15 Positions by Absolute Weight')\n",
    "axes[1, 0].set_xlabel('Absolute Weight')\n",
    "\n",
    "# Risk exposure\n",
    "axes[1, 1].pie([weights.abs().sum(), 1 - weights.abs().sum()], \n",
    "               labels=['Invested', 'Cash'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 1].set_title('Portfolio Utilization')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Backtesting {#backtest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive backtest\n",
    "print(\"üöÄ Running backtest...\")\n",
    "results = backtester.run_backtest(tickers=tickers, use_shrinkage=True, use_lasso=True)\n",
    "\n",
    "if results:\n",
    "    print(\"\\nüìä Backtest Results:\")\n",
    "    metrics = results['metrics']\n",
    "    \n",
    "    print(f\"  Total Return: {metrics['total_return']:.2%}\")\n",
    "    print(f\"  Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "    print(f\"  Volatility: {metrics['volatility']:.2%}\")\n",
    "    print(f\"  Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  Maximum Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"  Win Rate: {metrics['win_rate']:.2%}\")\n",
    "    print(f\"  Skewness: {metrics['skewness']:.2f}\")\n",
    "    print(f\"  Kurtosis: {metrics['kurtosis']:.2f}\")\n",
    "    print(f\"  Observations: {metrics['num_observations']}\")\n",
    "else:\n",
    "    print(\"‚ùå Backtest failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance visualization\n",
    "if results:\n",
    "    returns = results['returns']\n",
    "    gross_returns = results['gross_returns']\n",
    "    transaction_costs = results['transaction_costs']\n",
    "    \n",
    "    # Performance charts\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Cumulative returns\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    cum_gross_returns = (1 + gross_returns).cumprod()\n",
    "    \n",
    "    axes[0, 0].plot(cum_returns.index, cum_returns.values, label='Net Returns', linewidth=2)\n",
    "    axes[0, 0].plot(cum_gross_returns.index, cum_gross_returns.values, \n",
    "                    label='Gross Returns', linewidth=2, alpha=0.7)\n",
    "    axes[0, 0].set_title('Cumulative Returns')\n",
    "    axes[0, 0].set_ylabel('Cumulative Return')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rolling Sharpe ratio\n",
    "    rolling_sharpe = returns.rolling(60).mean() / returns.rolling(60).std() * np.sqrt(252)\n",
    "    axes[0, 1].plot(rolling_sharpe.index, rolling_sharpe.values, color='orange', linewidth=2)\n",
    "    axes[0, 1].set_title('Rolling Sharpe Ratio (60-day)')\n",
    "    axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Drawdown\n",
    "    rolling_max = cum_returns.expanding().max()\n",
    "    drawdown = (cum_returns / rolling_max) - 1\n",
    "    axes[0, 2].fill_between(drawdown.index, drawdown.values, 0, alpha=0.3, color='red')\n",
    "    axes[0, 2].set_title('Drawdown')\n",
    "    axes[0, 2].set_ylabel('Drawdown')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Return distribution\n",
    "    axes[1, 0].hist(returns, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1, 0].set_title('Return Distribution')\n",
    "    axes[1, 0].set_xlabel('Return')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].axvline(returns.mean(), color='red', linestyle='--', alpha=0.7, label='Mean')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Transaction costs\n",
    "    axes[1, 1].plot(transaction_costs.index, transaction_costs.cumsum(), \n",
    "                    color='red', linewidth=2)\n",
    "    axes[1, 1].set_title('Cumulative Transaction Costs')\n",
    "    axes[1, 1].set_ylabel('Cumulative Costs')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rolling volatility\n",
    "    rolling_vol = returns.rolling(60).std() * np.sqrt(252)\n",
    "    axes[1, 2].plot(rolling_vol.index, rolling_vol.values, color='purple', linewidth=2)\n",
    "    axes[1, 2].set_title('Rolling Volatility (60-day)')\n",
    "    axes[1, 2].set_ylabel('Annualized Volatility')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Walk-Forward Analysis {#walkforward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward out-of-sample analysis\n",
    "print(\"üîÑ Running walk-forward analysis...\")\n",
    "oos_results = backtester.walk_forward_analysis(\n",
    "    tickers=tickers,\n",
    "    initial_window=252,  # 1 year initial training\n",
    "    step_size=21  # Monthly steps\n",
    ")\n",
    "\n",
    "if oos_results:\n",
    "    print(\"\\nüìä Out-of-Sample Results:\")\n",
    "    oos_metrics = oos_results['oos_metrics']\n",
    "    \n",
    "    print(f\"  OOS Total Return: {oos_metrics['total_return']:.2%}\")\n",
    "    print(f\"  OOS Annualized Return: {oos_metrics['annualized_return']:.2%}\")\n",
    "    print(f\"  OOS Volatility: {oos_metrics['volatility']:.2%}\")\n",
    "    print(f\"  OOS Sharpe Ratio: {oos_metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  OOS Maximum Drawdown: {oos_metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"  OOS Win Rate: {oos_metrics['win_rate']:.2%}\")\n",
    "    print(f\"  OOS Observations: {oos_metrics['num_observations']}\")\n",
    "else:\n",
    "    print(\"‚ùå Walk-forward analysis failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in-sample vs out-of-sample performance\n",
    "if results and oos_results:\n",
    "    comparison_data = {\n",
    "        'Metric': ['Total Return', 'Annualized Return', 'Volatility', 'Sharpe Ratio', 'Max Drawdown'],\n",
    "        'In-Sample': [\n",
    "            results['metrics']['total_return'],\n",
    "            results['metrics']['annualized_return'],\n",
    "            results['metrics']['volatility'],\n",
    "            results['metrics']['sharpe_ratio'],\n",
    "            results['metrics']['max_drawdown']\n",
    "        ],\n",
    "        'Out-of-Sample': [\n",
    "            oos_results['oos_metrics']['total_return'],\n",
    "            oos_results['oos_metrics']['annualized_return'],\n",
    "            oos_results['oos_metrics']['volatility'],\n",
    "            oos_results['oos_metrics']['sharpe_ratio'],\n",
    "            oos_results['oos_metrics']['max_drawdown']\n",
    "        ]\n",
    "
